{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "330800fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from docopt import docopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e02a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_object(base, obj,filenamebase,filename_object, result):\n",
    "    # Find SIFT descriptors for both base and object images\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypts_base, descr_base = sift.detectAndCompute(filenamebase, None)\n",
    "    \n",
    "    keypts_obj, descr_obj = sift.detectAndCompute(filename_object, None)\n",
    " \n",
    "    \n",
    "    # Create and execute brute-force k-nn matching on descriptors\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks=50)   # or pass empty dictionary\n",
    "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(descr_obj, descr_base, k=2)\n",
    "    \n",
    "    # matches = cv2.BFMatcher().knnMatch(descr_obj, descr_base, k=2)\n",
    "    matches = [ [i] for i, j in matches if i.distance < 0.75*j.distance]\n",
    "#     print(obj[\"name\"])\n",
    "    if len(matches) > 10:\n",
    "        src_pts = np.float32([ keypts_obj[m[0].queryIdx].pt for m in matches]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ keypts_base[m[0].trainIdx].pt for m in matches]).reshape(-1,1,2)\n",
    "\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "        h, w, d = filename_object.shape\n",
    "        pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "        dst = np.int32(cv2.perspectiveTransform(pts, M))\n",
    "\n",
    "        matching_top_point = tuple(dst[np.argmin([x[0][1] for x in dst])][0])\n",
    "        result = cv2.polylines(result, [dst], True, (100,250,200), 1, cv2.LINE_AA)\n",
    "        cv2.putText(result, obj[\"name\"], matching_top_point, cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.7, (255,255,255), 1)\n",
    "    else:\n",
    "        print(\"Could not find any satisfying matches for {}\".format(obj[\"name\"]))\n",
    "        return False\n",
    "\n",
    "    matching_img = cv2.drawMatchesKnn(filename_object, keypts_obj, filenamebase, keypts_base, matches, None, flags=2)\n",
    "    \n",
    "#     cv2.imshow('Feature matching for {}'.format(obj), matching_img)\n",
    "#     if cv2.waitKey(0) & 0xff == 27:\n",
    "#         cv2.destroyAllWindows()\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d2a962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_objects(base, objects):    \n",
    "    result = base[\"image\"].copy()\n",
    "    found_objects = []\n",
    "    for obj in objects:\n",
    "        if find_object(base, obj, filenamebase,filename_object, result) == True:\n",
    "             found_objects.append(obj[\"name\"])\n",
    "    cv2.imshow('Final result for {} (objects found: {})'.format(base[\"name\"], \", \".join(found_objects)), result)\n",
    "    if cv2.waitKey(0) :\n",
    "        cv2.destroyAllWindows()    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857a2735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of images you want to use:\n",
      "2\n",
      "Enter the image name\n",
      "Enter the objects 1 image:\n",
      "airpods1.jpg\n",
      "Enter the objects 2 image:\n",
      "control.jpg\n",
      "Enter the base image:\n",
      "img_query_3.jpg\n",
      "[[[184 184 184]\n",
      "  [187 187 187]\n",
      "  [188 188 188]\n",
      "  ...\n",
      "  [172 170 170]\n",
      "  [175 173 173]\n",
      "  [178 176 176]]\n",
      "\n",
      " [[175 175 175]\n",
      "  [177 177 177]\n",
      "  [179 179 179]\n",
      "  ...\n",
      "  [172 170 170]\n",
      "  [175 173 173]\n",
      "  [178 176 176]]\n",
      "\n",
      " [[178 178 178]\n",
      "  [178 178 178]\n",
      "  [177 177 177]\n",
      "  ...\n",
      "  [176 174 174]\n",
      "  [175 173 173]\n",
      "  [176 174 174]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[192 186 179]\n",
      "  [192 186 179]\n",
      "  [193 187 180]\n",
      "  ...\n",
      "  [195 193 192]\n",
      "  [195 193 192]\n",
      "  [195 193 192]]\n",
      "\n",
      " [[191 185 178]\n",
      "  [190 184 177]\n",
      "  [193 187 180]\n",
      "  ...\n",
      "  [194 192 191]\n",
      "  [196 194 193]\n",
      "  [196 194 193]]\n",
      "\n",
      " [[191 185 178]\n",
      "  [190 184 177]\n",
      "  [193 187 180]\n",
      "  ...\n",
      "  [194 192 191]\n",
      "  [196 194 193]\n",
      "  [196 194 193]]]\n",
      "{'name': 'img_query_3', 'image': array([[[ 92, 108, 114],\n",
      "        [ 70,  86,  92],\n",
      "        [ 73,  89,  95],\n",
      "        ...,\n",
      "        [ 45,  67,  85],\n",
      "        [ 43,  65,  83],\n",
      "        [ 42,  64,  82]],\n",
      "\n",
      "       [[ 95, 111, 117],\n",
      "        [ 85, 101, 107],\n",
      "        [ 71,  87,  93],\n",
      "        ...,\n",
      "        [ 43,  63,  81],\n",
      "        [ 47,  67,  85],\n",
      "        [ 43,  63,  81]],\n",
      "\n",
      "       [[ 84, 100, 106],\n",
      "        [ 80,  96, 102],\n",
      "        [ 71,  87,  93],\n",
      "        ...,\n",
      "        [ 47,  67,  85],\n",
      "        [ 45,  65,  83],\n",
      "        [ 45,  65,  83]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 69,  86,  99],\n",
      "        [ 68,  85,  98],\n",
      "        [ 68,  85,  98],\n",
      "        ...,\n",
      "        [124, 161, 187],\n",
      "        [126, 164, 188],\n",
      "        [125, 166, 188]],\n",
      "\n",
      "       [[ 68,  85,  98],\n",
      "        [ 63,  80,  93],\n",
      "        [ 60,  79,  92],\n",
      "        ...,\n",
      "        [131, 168, 196],\n",
      "        [132, 171, 199],\n",
      "        [135, 175, 200]],\n",
      "\n",
      "       [[ 57,  75,  86],\n",
      "        [ 61,  79,  90],\n",
      "        [ 59,  77,  88],\n",
      "        ...,\n",
      "        [135, 172, 200],\n",
      "        [131, 168, 194],\n",
      "        [133, 174, 197]]], dtype=uint8)}\n",
      "[{'name': 'airpods1'}, {'name': 'control'}]\n",
      "airpods1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@21.406] global shadow_sift.hpp:13 SIFT_create DEPRECATED: cv.xfeatures2d.SIFT_create() is deprecated due SIFT tranfer to the main repository. https://github.com/opencv/opencv/issues/16736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Enter the number of images you want to use:\")\n",
    "    no_of_images = int(input())\n",
    "    print(\"Enter the image name\")\n",
    "    \n",
    "    filename = []\n",
    "    for i in range(no_of_images):\n",
    "        print(\"Enter the objects %d image:\" %(i+1))\n",
    "        filename.append(input())\n",
    "\n",
    "    images_objects = []\n",
    "    for file in filename:\n",
    "        images_objects.append(cv2.imread(file))\n",
    "\n",
    "    \n",
    "#     filename_base = []\n",
    "    print(\"Enter the base image:\")\n",
    "    filename_base = input()\n",
    "\n",
    "    # Load the base image\n",
    "    image_base = cv2.imread(filename_base)\n",
    "# img_query_1.jpg\n",
    "#     print(filename_base[0].split('.')[0])\n",
    "#     print(filename_base[0].split('.')[0])\n",
    "#     print(filename_base[0].split('.')[0])\n",
    "    split=[i.split('.')[0] for i in filename]\n",
    "    split1=[i.split('.')[0] for i in filename_base]\n",
    "#     print(split)\n",
    "    filenamebase=cv2.imread(filename_base)\n",
    "#     print(filenamebase)\n",
    "    filename_object=cv2.imread(file) \n",
    "    print(filename_object)\n",
    "    base  = {\"name\": filename_base.split('.')[0],\"image\":filenamebase}\n",
    "    objects = [{\"name\": name} for name in split] \n",
    "\n",
    "    print(base)\n",
    "    print(objects)\n",
    "\n",
    "    find_objects(base, objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a56132f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9433e58b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99c39d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
